# this is a sample for keys used in this code repo. 
# Please rename it to .env before you can use it

# basic info
MODEL_PROVIDER=azureopenai  # azureopenai, bedrock, openai, azureml, azureaifoundry, huggingface
MODEL_NAME=gpt-5.1
MODEL_VERSION=2025-12-11
IS_DEBUG=false

# Reasoning Configuration (applies to all providers)
REASONING_ENABLED=false
REASONING_EFFORT=medium # none(5.1), minimal, low, medium, high

# Azure Open AI - See https://learn.microsoft.com/en-us/azure/ai-services/openai/api-version-deprecation
AZURE_OPENAI_ENDPOINT=https://xxx.openai.azure.com/
AZURE_OPENAI_API_KEY=xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
AZURE_OPENAI_DEPLOYMENT_NAME=gpt-5.1
AZURE_OPENAI_API_VERSION=2025-04-01-preview

# OpenAI
OPENAI_API_KEY=xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
OPENAI_DEPLOYMENT_NAME=xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx

# Hugging Face
HF_API_TOKEN=xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx

# Azure ML
AZURE_ML_DEPLOYMENT_NAME=xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
AZURE_ML_ENDPOINT_URL=xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
AZURE_ML_ENDPOINT_TYPE=xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
AZURE_ML_API_KEY=xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx

# Azure AI Foundry (Azure AI Inference)
AZURE_AI_INFERENCE_KEY=xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
AZURE_AI_INFERENCE_ENDPOINT=

AZURE_AI_DEPLOYMENT_NAME=Phi-4

# AWS Bedrock
BEDROCK_MODEL_ID=qwen.qwen3-next-80b-a3b
AWS_REGION=us-east-1

# Wait time between requests (seconds) - helps avoid throttling
WAIT_TIME=30